{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "from tqdm import tqdm, notebook\n",
    "from time import sleep\n",
    "import pymorphy2\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import torch\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('datasets/toxic_comments.csv', index_col=0)\n",
    "except FileNotFoundError: \n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_sample = data.sample(n=data.shape[0])\n",
    "# data_sample.reset_index(inplace=True, drop=True)\n",
    "# data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_string(text):\n",
    "    text = re.sub(r'[^A-Za-z]', ' ', text)\n",
    "    text = text.lower().replace('/n', ' ').split()\n",
    "    \n",
    "    for word in text:\n",
    "        if len(word) < 3:\n",
    "            text.remove(word)\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "def lemmatize_spacy(text):\n",
    "    return \" \".join([token.lemma_ for token in nlp(text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация и очистка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [00:06<00:00, 23069.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         explanation why the edits made under username ...\n",
       "1         aww matches this background colour m seemingly...\n",
       "2         hey man m really not trying edit war s just th...\n",
       "3         more can make any real suggestions improvement...\n",
       "4         you sir are hero any chance you remember what ...\n",
       "                                ...                        \n",
       "159287    and for the second time asking when your view ...\n",
       "159288    you should ashamed yourself that a horrible th...\n",
       "159289    spitzer umm theres actual article for prostitu...\n",
       "159290    and looks like was actually you who put the sp...\n",
       "159291    and really don think you understand came here ...\n",
       "Name: text, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_corpus = data['text'].progress_apply(prepare_string)\n",
    "X_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [11:17<00:00, 235.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         explanation why the edit make under username h...\n",
       "1         aww match this background colour m seemingly s...\n",
       "2         hey man m really not try edit war s just that ...\n",
       "3         more can make any real suggestion improvement ...\n",
       "4         you sir be hero any chance you remember what p...\n",
       "                                ...                        \n",
       "159287    and for the second time ask when your view com...\n",
       "159288    you should ashamed yourself that a horrible th...\n",
       "159289    spitzer umm there s actual article for prostit...\n",
       "159290    and look like be actually you who put the spee...\n",
       "159291    and really don think you understand come here ...\n",
       "Name: text, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_corpus_lemma = X_corpus.progress_apply(lemmatize_spacy)\n",
    "X_corpus_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mig29fulcrum\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делим выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_corpus_lemma, data['toxic'], test_size=0.1, stratify=data['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вычисление TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"clf\", LogisticRegression(max_iter=10000, class_weight='balanced')),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pipe = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"clf\", LGBMClassifier()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7524863651573724, 0.0014079186484297864)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_lr = cross_val_score(estimator=lr_pipe, \n",
    "                           X=X_train, \n",
    "                           y=y_train, \n",
    "                           cv=StratifiedKFold(5, shuffle=True),\n",
    "                           error_score='raise',\n",
    "                           scoring='f1')\n",
    "cross_lr.mean(), cross_lr.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7518180521453741, 0.004292083280278978)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_lgbm = cross_val_score(lgbm_pipe, \n",
    "                                  X=X_train, \n",
    "                                  y=y_train, \n",
    "                                  cv=StratifiedKFold(5, shuffle=True),  \n",
    "                                  scoring='f1')\n",
    "cross_lgbm.mean(), cross_lgbm.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Выбираем логистическую регрессию (метрика лучше и разница по фолдам меньше)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptHyperparams:\n",
    "    def __init__ (self, \n",
    "                  estimator, \n",
    "                  space=dict(),\n",
    "                  other_params=dict(), \n",
    "                  cv=5, \n",
    "                  max_evals=20, \n",
    "                  scoring='neg_log_loss'):\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        self.space=space\n",
    "        self.other_params = other_params\n",
    "        self.cv=cv\n",
    "        self.max_evals = max_evals\n",
    "        self.scoring = scoring\n",
    "        \n",
    "    def __cross_val__(self, params):\n",
    "        cross_val = cross_val_score(self.estimator(**params, **self.other_params), \n",
    "                        X=self.X, \n",
    "                        y=self.y,           \n",
    "                        scoring=self.scoring,\n",
    "                        cv=self.cv,\n",
    "                        error_score='raise'\n",
    "                       )\n",
    "        result = {'loss': -cross_val.mean(), 'status': STATUS_OK}\n",
    "\n",
    "        print(f'Средний {self.scoring}: {cross_val.mean():.4f}')\n",
    "        print(f'Стандартное отклонение по фолдам: {cross_val.std():.4f}')\n",
    "        print(f'Tекущие параметры: {params}')\n",
    "        return result\n",
    "\n",
    "\n",
    "    def __get_best_params__(self):\n",
    "\n",
    "        best_params = fmin(self.__cross_val__, \n",
    "                           space = self.space, \n",
    "                           algo=tpe.suggest, \n",
    "                           trials=Trials(), \n",
    "                           max_evals=self.max_evals)\n",
    "        print ('Лучшие гиперпараметры:', best_params)\n",
    "        return best_params\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.model = self.estimator(**self.__get_best_params__(), **self.other_params)\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "    def predict(self, X_pred):\n",
    "        return self.model.predict(X_pred)\n",
    "    \n",
    "#     def predict_proba(self, X_pred_prob):\n",
    "#         return self.model.predict_proba(X_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_lr= {\n",
    "    'C' : hp.lognormal('C', 0, 1), \n",
    "    # 'penalty' : hp.choice('penalty', ['l1','l2']),\n",
    "    # 'class_weight' : hp.choice('class_weight', ['balanced', None,])\n",
    "}\n",
    "\n",
    "other_params_lr = {\n",
    "    'max_iter' : 10000,\n",
    "    'solver': 'liblinear',\n",
    "    'class_weight' : 'balanced'\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid_pipe = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer(stop_words=stopwords)),\n",
    "        (\"clf\",  OptHyperparams(LogisticRegression,\n",
    "                                space=space_lr, \n",
    "                                other_params=other_params_lr,\n",
    "                                max_evals=20, \n",
    "                                scoring='f1', \n",
    "                                cv = StratifiedKFold(n_splits=5, shuffle=True),\n",
    "                               )\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний f1: 0.7511                                    \n",
      "Стандартное отклонение по фолдам: 0.0016              \n",
      "Tекущие параметры: {'C': 0.7762759041144033}          \n",
      "Средний f1: 0.7457                                                               \n",
      "Стандартное отклонение по фолдам: 0.0063                                         \n",
      "Tекущие параметры: {'C': 0.6107760237790363}                                     \n",
      "Средний f1: 0.7355                                                               \n",
      "Стандартное отклонение по фолдам: 0.0040                                         \n",
      "Tекущие параметры: {'C': 0.28358727735875916}                                    \n",
      "Средний f1: 0.7606                                                               \n",
      "Стандартное отклонение по фолдам: 0.0032                                         \n",
      "Tекущие параметры: {'C': 1.694356719428899}                                      \n",
      "Средний f1: 0.7439                                                               \n",
      "Стандартное отклонение по фолдам: 0.0038                                         \n",
      "Tекущие параметры: {'C': 0.5048975449458412}                                     \n",
      "Средний f1: 0.7335                                                               \n",
      "Стандартное отклонение по фолдам: 0.0058                                         \n",
      "Tекущие параметры: {'C': 0.25720975181906475}                                    \n",
      "Средний f1: 0.7472                                                               \n",
      "Стандартное отклонение по фолдам: 0.0049                                         \n",
      "Tекущие параметры: {'C': 0.5937120152318991}                                     \n",
      "Средний f1: 0.7639                                                               \n",
      "Стандартное отклонение по фолдам: 0.0026                                         \n",
      "Tекущие параметры: {'C': 2.3386851600329166}                                     \n",
      "Средний f1: 0.7495                                                               \n",
      "Стандартное отклонение по фолдам: 0.0065                                         \n",
      "Tекущие параметры: {'C': 0.7514993157584294}                                     \n",
      "Средний f1: 0.7604                                                               \n",
      "Стандартное отклонение по фолдам: 0.0050                                         \n",
      "Tекущие параметры: {'C': 1.82082322311936}                                       \n",
      "Средний f1: 0.7360                                                                \n",
      "Стандартное отклонение по фолдам: 0.0045                                          \n",
      "Tекущие параметры: {'C': 0.3157532111576318}                                      \n",
      "Средний f1: 0.7169                                                                \n",
      "Стандартное отклонение по фолдам: 0.0082                                          \n",
      "Tекущие параметры: {'C': 0.1128012616016486}                                      \n",
      "Средний f1: 0.7292                                                                \n",
      "Стандартное отклонение по фолдам: 0.0081                                          \n",
      "Tекущие параметры: {'C': 0.21574414917441181}                                     \n",
      "Средний f1: 0.7574                                                                \n",
      "Стандартное отклонение по фолдам: 0.0029                                          \n",
      "Tекущие параметры: {'C': 1.2866386025310979}                                      \n",
      "Средний f1: 0.7303                                                                \n",
      "Стандартное отклонение по фолдам: 0.0067                                          \n",
      "Tекущие параметры: {'C': 0.22519199424398023}                                     \n",
      "Средний f1: 0.7301                                                                \n",
      "Стандартное отклонение по фолдам: 0.0035                                          \n",
      "Tекущие параметры: {'C': 0.21844291893531237}                                     \n",
      "Средний f1: 0.7474                                                                \n",
      "Стандартное отклонение по фолдам: 0.0050                                          \n",
      "Tекущие параметры: {'C': 0.6279495546848577}                                      \n",
      "Средний f1: 0.7445                                                                \n",
      "Стандартное отклонение по фолдам: 0.0031                                          \n",
      "Tекущие параметры: {'C': 0.4657069070329292}                                      \n",
      "Средний f1: 0.7604                                                                \n",
      "Стандартное отклонение по фолдам: 0.0033                                          \n",
      "Tекущие параметры: {'C': 1.7375050688056075}                                      \n",
      "Средний f1: 0.7523                                                                \n",
      "Стандартное отклонение по фолдам: 0.0027                                          \n",
      "Tекущие параметры: {'C': 0.9034240026010374}                                      \n",
      "100%|██████████| 20/20 [01:51<00:00,  5.59s/trial, best loss: -0.7639362950153901]\n",
      "Лучшие гиперпараметры: {'C': 2.3386851600329166}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('clf',\n",
       "                 <__main__.OptHyperparams object at 0x000001C572CB89A0>)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7575338678462814"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, lr_grid_pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Подбор параметров немного улучшил метрику\n",
    "* Целевая метрика достигнута"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/toxic_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.sample(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 630.50it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.BertTokenizer(\n",
    "    vocab_file='datasets/ds_bert/vocab.txt')\n",
    "\n",
    "tokenized = data['text'].progress_apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512,))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at unitary/toxic-bert and are newly initialized because the shapes did not match:\n",
      "- bert.embeddings.word_embeddings.weight: found shape torch.Size([30522, 768]) in the checkpoint and torch.Size([28996, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = transformers.BertConfig.from_json_file(\n",
    "    'datasets/ds_bert/bert_config.json')\n",
    "model = transformers.BertModel.from_pretrained('unitary/toxic-bert', \n",
    "                                               config=config,  \n",
    "                                               ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7733a8211e4f259c81f5b5d8887544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 200\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:, 0, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.5, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(X_train, y_train)\n",
    "test_pool = Pool(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5580357142857143, 1: 4.8076923076923075}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "print(class_weights)\n",
    "\n",
    "clf = CatBoostClassifier(devices='GPU', \n",
    "                         silent=True, \n",
    "                         eval_metric='F1',\n",
    "                         class_weights=class_weights, \n",
    "                         n_estimators=2000, \n",
    "                         learning_rate=0.001, \n",
    "                         max_depth=2\n",
    "                         \n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad3baf8a1ea4913b772316ce1a7fb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1c50b04be50>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_pool, \n",
    "        plot=True, \n",
    "        eval_set=test_pool, \n",
    "        #use_best_model=True,\n",
    "        #early_stopping_rounds=100\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier(devices='GPU', \n",
    "                         silent=True, \n",
    "                         eval_metric='TotalF1',\n",
    "                         #class_weights=class_weights, \n",
    "                         n_estimators=200, \n",
    "                         #learning_rate=0.1, \n",
    "                         #max_depth=4\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b19c8565b4a4a5ba299c8bbba7eb01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1c50d456d60>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_pool,\n",
    "        plot=True, \n",
    "        eval_set=test_pool,\n",
    "       #use_best_model=True\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Целевая метрика достигнута."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
